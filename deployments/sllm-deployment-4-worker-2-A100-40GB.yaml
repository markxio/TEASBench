# ---------------------------------------------------------------------------- #
#  ServerlessLLM v1-beta Kubernetes Deployment                                 #
#  Configuration: 4 Workers × 2 A100-40GB GPUs                                 #
#                                                                              #
#  Resources:                                                                  #
#    - Total GPUs: 9 (8 A100-40GB + 1 MIG)                                    #
#    - Total CPU: 84 (4 + 16 + 4×16)                                          #
#    - Total RAM: 648GB (8 + 128 + 4×128)                                     #
# ---------------------------------------------------------------------------- #
---
# Service for Pylet Head (cluster manager)
apiVersion: v1
kind: Service
metadata:
  name: pylet-head
  labels:
    app: pylet-head
spec:
  type: ClusterIP
  ports:
    - name: pylet
      port: 8000
      targetPort: 8000
  selector:
    app: pylet-head
---
# Service for SLLM Head (control plane)
apiVersion: v1
kind: Service
metadata:
  name: sllm-head
  labels:
    app: sllm-head
spec:
  type: ClusterIP
  ports:
    - name: sllm
      port: 8343
      targetPort: 8343
  selector:
    app: sllm-head
---
# Pylet Head Deployment (cluster manager)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pylet-head
  labels:
    app: pylet-head
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pylet-head
  template:
    metadata:
      labels:
        app: pylet-head
        kueue.x-k8s.io/queue-name: eidf230ns-user-queue
    spec:
      containers:
        - name: pylet-head
          image: python:3.10-slim
          command:
            - /bin/sh
            - -c
            - |
              pip install pylet httpx &&
              pylet start
          ports:
            - containerPort: 8000
          resources:
            requests:
              cpu: 4
              memory: '8Gi'
            limits:
              cpu: 4
              memory: '8Gi'
          readinessProbe:
            httpGet:
              path: /workers
              port: 8000
            initialDelaySeconds: 15
            periodSeconds: 5
            timeoutSeconds: 5
            failureThreshold: 10
          livenessProbe:
            httpGet:
              path: /workers
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
---
# SLLM Head Deployment (control plane)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sllm-head
  labels:
    app: sllm-head
spec:
  replicas: 1
  selector:
    matchLabels:
      app: sllm-head
  template:
    metadata:
      labels:
        app: sllm-head
        kueue.x-k8s.io/queue-name: eidf230ns-user-queue
    spec:
      nodeSelector:
        nvidia.com/gpu.product: "NVIDIA-A100-SXM4-40GB-MIG-3g.20gb"
      containers:
        - name: sllm-head
          image: seanjiang01/sllm:latest
          ports:
            - containerPort: 8343
          env:
            - name: MODE
              value: "HEAD"
            - name: PYLET_ENDPOINT
              value: "http://pylet-head:8000"
            - name: STORAGE_PATH
              value: "/models"
            - name: SLLM_DATABASE_PATH
              value: "/models/.sllm/state.db"
            - name: SGLANG_EXPERT_DISTRIBUTION_RECORDER_DIR
              value: "/models/expert_records"
          volumeMounts:
            - name: model-storage
              mountPath: /models
          resources:
            requests:
              cpu: 16
              memory: '128Gi'
            limits:
              cpu: 16
              memory: '128Gi'
              nvidia.com/gpu: "1"
          readinessProbe:
            httpGet:
              path: /health
              port: 8343
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 6
          livenessProbe:
            httpGet:
              path: /health
              port: 8343
            initialDelaySeconds: 60
            periodSeconds: 20
            timeoutSeconds: 10
            failureThreshold: 3
      volumes:
        - name: model-storage
          persistentVolumeClaim:
            claimName: model-pvc
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
---
# Worker 0
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pylet-worker-0
  labels:
    app: pylet-worker
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pylet-worker
      worker-id: "0"
  template:
    metadata:
      labels:
        app: pylet-worker
        worker-id: "0"
        kueue.x-k8s.io/queue-name: eidf230ns-user-queue
    spec:
      nodeSelector:
        nvidia.com/gpu.product: "NVIDIA-A100-SXM4-40GB"
      containers:
        - name: pylet-worker
          image: seanjiang01/sllm:latest
          env:
            - name: MODE
              value: "PYLET_WORKER"
            - name: PYLET_HEAD
              value: "pylet-head:8000"
            - name: GPU_UNITS
              value: "2"
            - name: STORAGE_PATH
              value: "/models"
          volumeMounts:
            - name: model-storage
              mountPath: /models
            - name: shm
              mountPath: /dev/shm
          resources:
            requests:
              cpu: 16
              memory: '128Gi'
            limits:
              cpu: 16
              memory: '128Gi'
              nvidia.com/gpu: "2"
      volumes:
        - name: model-storage
          persistentVolumeClaim:
            claimName: model-pvc
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
---
# Worker 1
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pylet-worker-1
  labels:
    app: pylet-worker
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pylet-worker
      worker-id: "1"
  template:
    metadata:
      labels:
        app: pylet-worker
        worker-id: "1"
        kueue.x-k8s.io/queue-name: eidf230ns-user-queue
    spec:
      nodeSelector:
        nvidia.com/gpu.product: "NVIDIA-A100-SXM4-40GB"
      containers:
        - name: pylet-worker
          image: seanjiang01/sllm:latest
          env:
            - name: MODE
              value: "PYLET_WORKER"
            - name: PYLET_HEAD
              value: "pylet-head:8000"
            - name: GPU_UNITS
              value: "2"
            - name: STORAGE_PATH
              value: "/models"
          volumeMounts:
            - name: model-storage
              mountPath: /models
            - name: shm
              mountPath: /dev/shm
          resources:
            requests:
              cpu: 16
              memory: '128Gi'
            limits:
              cpu: 16
              memory: '128Gi'
              nvidia.com/gpu: "2"
      volumes:
        - name: model-storage
          persistentVolumeClaim:
            claimName: model-pvc
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
---
# Worker 2
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pylet-worker-2
  labels:
    app: pylet-worker
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pylet-worker
      worker-id: "2"
  template:
    metadata:
      labels:
        app: pylet-worker
        worker-id: "2"
        kueue.x-k8s.io/queue-name: eidf230ns-user-queue
    spec:
      nodeSelector:
        nvidia.com/gpu.product: "NVIDIA-A100-SXM4-40GB"
      containers:
        - name: pylet-worker
          image: seanjiang01/sllm:latest
          env:
            - name: MODE
              value: "PYLET_WORKER"
            - name: PYLET_HEAD
              value: "pylet-head:8000"
            - name: GPU_UNITS
              value: "2"
            - name: STORAGE_PATH
              value: "/models"
          volumeMounts:
            - name: model-storage
              mountPath: /models
            - name: shm
              mountPath: /dev/shm
          resources:
            requests:
              cpu: 16
              memory: '128Gi'
            limits:
              cpu: 16
              memory: '128Gi'
              nvidia.com/gpu: "2"
      volumes:
        - name: model-storage
          persistentVolumeClaim:
            claimName: model-pvc
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
---
# Worker 3
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pylet-worker-3
  labels:
    app: pylet-worker
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pylet-worker
      worker-id: "3"
  template:
    metadata:
      labels:
        app: pylet-worker
        worker-id: "3"
        kueue.x-k8s.io/queue-name: eidf230ns-user-queue
    spec:
      nodeSelector:
        nvidia.com/gpu.product: "NVIDIA-A100-SXM4-40GB"
      containers:
        - name: pylet-worker
          image: seanjiang01/sllm:latest
          env:
            - name: MODE
              value: "PYLET_WORKER"
            - name: PYLET_HEAD
              value: "pylet-head:8000"
            - name: GPU_UNITS
              value: "2"
            - name: STORAGE_PATH
              value: "/models"
          volumeMounts:
            - name: model-storage
              mountPath: /models
            - name: shm
              mountPath: /dev/shm
          resources:
            requests:
              cpu: 16
              memory: '128Gi'
            limits:
              cpu: 16
              memory: '128Gi'
              nvidia.com/gpu: "2"
      volumes:
        - name: model-storage
          persistentVolumeClaim:
            claimName: model-pvc
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
