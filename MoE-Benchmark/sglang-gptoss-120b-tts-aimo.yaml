apiVersion: batch/v1
kind: Job
metadata:
  generateName: sglang-tirsc-7-parametersearch-
  namespace: eidf230ns
  labels:
    kueue.x-k8s.io/queue-name: eidf230ns-user-queue
spec:
  backoffLimit: 0
  template:
    metadata:
      name: sglang-tirsc-7-pod
    spec:
      restartPolicy: Never
      securityContext:
        fsGroup: 2000

      # Uncomment if GHCR package is private:
      # imagePullSecrets:
      #   - name: ghcr-pull

      initContainers:
        # Wait for pylet head to be ready
        - name: wait-for-pylet-head
          image: curlimages/curl:latest
          command:
            - /bin/sh
            - -c
            - |
              echo "Waiting for pylet-head to be ready..."
              until curl -sf http://pylet-head:8000/workers; do
                echo "Pylet head not ready yet, retrying in 10s..."
                sleep 10
              done
              echo "Pylet head is ready!"
          resources:
            requests:
              cpu: 1
              memory: '1Gi'
            limits:
              cpu: 1
              memory: '1Gi'
        # Wait for the sllm head node to be ready
        - name: wait-for-head
          image: curlimages/curl:latest
          command:
            - /bin/sh
            - -c
            - |
              echo "Waiting for sllm-head to be ready..."
              until curl -sf http://sllm-head:8343/health; do
                echo "Head node not ready yet, retrying in 10s..."
                sleep 10
              done
              echo "Head node is ready!"
          resources:
            requests:
              cpu: 1
              memory: '1Gi'
            limits:
              cpu: 1
              memory: '1Gi'
        # Wait for worker to register
        - name: wait-for-worker
          image: curlimages/curl:latest
          command:
            - /bin/sh
            - -c
            - |
              echo "Waiting for pylet worker to register (60s)..."
              sleep 60
              echo "Worker should be registered now."
          resources:
            requests:
              cpu: 1
              memory: '1Gi'
            limits:
              cpu: 1
              memory: '1Gi'

      containers:
        - name: runner
          image: ghcr.io/yufan196884/aimo3-sglang:pt2.9.1-cuda13-py312
          imagePullPolicy: Always

          env:
            - name: HF_HOME
              value: /workspace/hf_cache
            - name: HUGGINGFACE_HUB_CACHE
              value: /workspace/hf_cache/hub
            - name: TRANSFORMERS_CACHE
              value: /workspace/hf_cache/transformers
            - name: HF_DATASETS_CACHE
              value: /workspace/hf_cache/datasets
            - name: HF_HUB_ENABLE_HF_TRANSFER
              value: "1"
            - name: SLLM_DATABASE_PATH
              value: "/workspace/.sllm/state.db"
            - name: LLM_SERVER_URL
              value: "http://sllm-head:8343"

            - name: GITHUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: yufan-github-pat
                  key: GITHUB_TOKEN

          command: ["/bin/bash","-lc"]
          args:
            - |-
              set -euo pipefail
              export NCCL_IB_DISABLE=1

              sllm deploy --model unsloth/gpt-oss-120b \
                --config /etc/serverlessllm/config.json

              # PVC-backed caches
              mkdir -p /workspace/hf_cache/hub \
                       /workspace/hf_cache/transformers \
                       /workspace/hf_cache/datasets \
                       /workspace/pip_cache

              cd /workspace

              BRANCH="yufan"
              REPO_URL="https://yufan196884:${GITHUB_TOKEN}@github.com/yufan196884/aimo_3.git"

              if [ -d "aimo_3/.git" ]; then
                  echo "aimo_3 exists. Updating to origin/${BRANCH}..."
                  cd /workspace/aimo_3
                  git remote set-url origin "$REPO_URL"
                  git fetch --all --prune
                  git checkout -B "$BRANCH" "origin/$BRANCH"
                  git reset --hard "origin/$BRANCH"
              else
                  echo "Cloning aimo_3 branch ${BRANCH}..."
                  git clone --branch "$BRANCH" --single-branch "$REPO_URL" aimo_3
                  cd /workspace/aimo_3
              fi

              # Optional sanity check (fast)
              python - << 'PY'
              import sys
              print("python", sys.version)
              import torch
              print("torch", torch.__version__, "cuda", torch.version.cuda, "available", torch.cuda.is_available())
              import sglang
              print("sglang", getattr(sglang, "__version__", "unknown"))
              PY

              export PYTHONPATH="/workspace/aimo_3:${PYTHONPATH:-}"

              python -u "./inference_systems/eval_aimo_tirsc_7.py" \
                --model_path "unsloth/gpt-oss-120b" \
                --host "0.0.0.0" \
                --port 5000 \
                --log_level "warning" \
                --served_model_name "sglang_model" \
                --dtype "auto" \
                --kv_cache_dtype "auto" \
                --context_length 131072 \
                --mem_fraction_static 0.96 \
                --tp_size 1 \
                --dp_size 1 \
                --tool_call_parser "gpt-oss" \
                --reasoning_parser "gpt-oss" \
                --reasoning_effort high \
                --temperature 1.0 \
                --random_seed 10002026011702 \
                --top_p 1.0 \
                --max_new_tokens 16384 \
                --max_workers 4 \
                --majority_threshold 4 \
                --dataset_name imo_answerbench_algnt \
                --output_folder ./eval_aimo3/tirsc_7/gpt-oss-120b/ \
                --k 4 \
                --population 8 \
                --loops 3 \
                --reasoning_budget 65536 \
                --python_tool_timeout 5.0
                --base_url_override $LLM_SERVER_URL/v1/completions

          resources:
            requests:
              cpu: "2"
              memory: "32Gi"
            limits:
              cpu: "2"
              memory: "32Gi"

          volumeMounts:
            - name: llm-cache
              mountPath: /workspace
            - name: shm
              mountPath: /dev/shm

      volumes:
        - name: llm-cache
          persistentVolumeClaim:
            claimName: llm-cache-pvc
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
